{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from scipy import stats\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('your_dataset.csv')  # Replace with your actual data loading method\n",
    "\n",
    "def assess_noise(df):\n",
    "    # 1. Basic statistics and missing values\n",
    "    print(\"Basic Statistics:\")\n",
    "    print(df.describe())\n",
    "    print(\"\\nMissing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    # 2. Correlation analysis\n",
    "    corr_matrix = df.corr()\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, cmap='coolwarm', annot=False)\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "    # 3. Distribution of each feature\n",
    "    df.hist(figsize=(20, 20), bins=50)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 4. PCA for dimensionality assessment\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    pca = PCA()\n",
    "    pca.fit(scaled_data)\n",
    "    \n",
    "    cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "    plt.plot(cumulative_variance_ratio)\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "    plt.title('PCA Cumulative Explained Variance')\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Outlier detection using Isolation Forest\n",
    "    iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "    outliers = iso_forest.fit_predict(scaled_data)\n",
    "    print(f\"\\nNumber of potential outliers detected: {sum(outliers == -1)}\")\n",
    "\n",
    "    # 6. Skewness analysis\n",
    "    skewness = df.skew()\n",
    "    print(\"\\nSkewness of features:\")\n",
    "    print(skewness)\n",
    "\n",
    "    # 7. Feature-to-feature relationships\n",
    "    sns.pairplot(df.sample(1000), diag_kind='kde', plot_kws={'alpha': 0.2})\n",
    "    plt.show()\n",
    "\n",
    "# Run the assessment\n",
    "assess_noise(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
